# Парсер PEP (Python Enhancement Proposals)

## Описание проекта

Этот проект представляет собой парсер, реализованный с использованием фреймворка Scrapy, для извлечения данных с сайта Python Enhancement Proposals (PEP). Парсер собирает информацию о номере, названии и статусе каждого PEP, подсчитывает количество PEP по статусам и сохраняет результаты в CSV-файл. Проект обеспечивает надежную обработку данных и формирование итоговой статистики.

## Возможности

- Сбор данных о PEP: Извлекает номер, название и статус каждого PEP с сайта https://peps.python.org/.

- Подсчет статусов: Подсчитывает количество PEP для каждого статуса и итоговое количество.

- Сохранение результатов: Сохраняет статистику по статусам в CSV-файл с временной меткой в имени файла.


## Технологический стек

- Python: 3.9 или выше

- Библиотеки:

  - Scrapy: Для асинхронного парсинга веб-страниц.
  - csv: Для записи результатов в CSV-файл.
  - pathlib: Для работы с путями к файлам.
  - datetime: Для создания имен файлов с временными метками.
  - os: Для работы с файловой системой.
  - collections.defaultdict: Для подсчета статусов PEP.

## Установка

### 1. Клонируйте репозиторий:

```bash
git clone <url-репозитория>
cd <директория-репозитория>
```

### 2. Создайте виртуальное окружение (рекомендуется):
```bash
python -m venv venv
source venv/bin/activate  # Для Windows: venv\Scripts\activate
```

### 3. Установите зависимости:
```bash
pip install -r requirements.txt
```

## Использование
Запустите парсер с помощью команды Scrapy:
```bash
scrapy crawl pep
```